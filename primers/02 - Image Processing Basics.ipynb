{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Processing Images\nAs far as computers are concerned, images are simply numerical data representations. You can use statistical techniques to manipulate and analyze the numerical properties of images.\n\n## Loading and Displaying an Image\nLet's start by loading a JPG file and examining its properties. Run the following cell to load and display an image using the **matplotlib.image** library."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from matplotlib import image as mpimg\nfrom matplotlib import pyplot as plt\nimport numpy as np\n%matplotlib inline\n\nimg1 = mpimg.imread('data/graeme.jpg')\nplt.imshow(img1)\ntype(img1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So we can see the file is definitely an image, but note that the data type of the **img1** object is actually a multidimensional numpy array.\n\nLet's take a closer look at the shape of this array:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "img1.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The image is actually composed of three \"layers, or *channels*, for red, green, and blue (RGB) pixel intensities. Each layer of the image represents 433 x 650 pixels (the dimensions of the image).\n\nNow let's load and display the same image but this time we'll use another popular Python library for working with images - **PIL**."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from PIL import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimg2 = Image.open('data/graeme.jpg')\nplt.imshow(img2)\ntype(img2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This time, the data type is a JpegImageFile - not a numpy array. That's great if we only want to manipulate it using PIL methods; but sometimes we'll want to be flexible and process images using multiple libraries; so we need a consistent format.\n\nFortunately, it's easy to convert a PIL JpegImageFile to a numpy array:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\n\nimg2 = np.array(img2)\nimg2.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also convert a numpy array to a PIL image, like this:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "img3 = Image.fromarray(img1)\nplt.imshow(img3)\ntype(img3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So fundamentally, the common format for image libraries is a numpy array. Using this as the standard format for your image processing workflow, converting to and from other formats as required, is the best way to take advantage of the particular strengths in each library while keeping your code consistent.\n\nYou can even save a numpy array in an optimized format, should you need to persist images into storage:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\n\n# Save the image\nnp.save('data/img.npy', img1)\n\n#Load the image\nimg4 = np.load('data/img.npy')\n\nplt.imshow(img4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Resizing an Image\nOne of the most common manipulations of an image is to resize it. This can be particularly important when you're preparing multiple images to train a machine learning model, as you'll generally want to ensure that all of your training images have consistent dimensions.\n\nLet's resize our image:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Load the image array into a PIL Image\norig_img = Image.fromarray(img4)\n\n# Get the image size\no_h, o_w = orig_img.size\nprint('Original size:', o_h, 'x', o_w)\n\n# We'll resize this so it's 200 x 200 using the thumbnail metho\ntarget_size = (200,200)\nnew_img = orig_img.resize(target_size)\nn_h, n_w = new_img.size\nprint('New size:', n_h, 'x', n_w)\n\n# Show the original and resized images\n# Create a figure\nfig = plt.figure(figsize=(12, 12))\n\n# Subplot for original image\na=fig.add_subplot(2,1,1)\nimgplot = plt.imshow(orig_img)\na.set_title('Before')\n\n# Subplot for resized image\na=fig.add_subplot(2,1,2)\nimgplot = plt.imshow(new_img)\na.set_title('After')\n\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Well, that worked; but notice that the image is not scaled. We resized the rectangular image to have square dimensions, and the image is skewed to fill the new size. If we want to resize the image and change its shape without distorting it, we'll need to *scale* the image so that its largest dimension fits our new desired size, and fill out any additional space with some sort of border."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from PIL import Image, ImageOps\n\n# We'll resize ththe image so it's 200 x 200\ntarget_size = (200,200)\n\n# Create a figure\nfig = plt.figure(figsize=(12, 12))\n\n# Load the original image\norig_img = Image.fromarray(img1)\norig_height, orig_width = orig_img.size\nprint('Original size:', orig_height, 'x', orig_width)\n# Plot the image\na=fig.add_subplot(3,1,1)\nimgplot = plt.imshow(orig_img)\na.set_title('Original')\n\n# Scale the image to the new size using the thumbnail method\nscaled_img = orig_img\nscaled_img.thumbnail(target_size, Image.ANTIALIAS)\nscaled_height, scaled_width = scaled_img.size\nprint('Scaled size:', scaled_height, 'x', scaled_width)\n# Plot the scaled image\na=fig.add_subplot(3,1,2)\nimgplot = plt.imshow(scaled_img)\na.set_title('Scaled')\n\n# Create a new white image of the target size to be the background\nnew_img = Image.new(\"RGB\", target_size, (255, 255, 255))\n# paste the scaled image into the center of the white background image\nnew_img.paste(scaled_img, (int((target_size[0] - scaled_img.size[0]) / 2), int((target_size[1] - scaled_img.size[1]) / 2)))\nnew_height, new_width = new_img.size\nprint('New size:', new_height, 'x', new_width)\n# Plot the resized image\na=fig.add_subplot(3,1,3)\nimgplot = plt.imshow(new_img)\na.set_title('Resized')\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Examining Numerical Properties of the Image Array\nSo we've seen that an image is inherently an array of values. Let's examine that in more detail. What type of values are in the array?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "img1.dtype",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "OK, so the array consists of 8-bit integer values. In other words, whole numbers between 0 and 255. These represent the possible pixel intensities for the RGB color channels in each pixel of the image."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's look at the distribution of pixel values in the image. Ideally, the image should have relatively even distribution of values, indicating good contrast and making it easier to extract analytical information.\n\nAn easy way to check this is to plot a histogram."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n%matplotlib inline\n\n# Plot a histogram - we need to use ravel to \"flatten\" the 3 dimensions\nplt.hist(img1.ravel())\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Another useful way to visualize the statistics of an image is as a cumulative distribution function (CDF) plot. Which shows the cumulative pixel intensity frequencies from 0 to 255."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.hist(img1.ravel(), bins=255, cumulative=True)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The histogram and CDF for our image show pretty uneven distribution - there's a lot of contrast in the image. Ideally we should equalize the values in the images we want to analyse to try to make our images more consistent in terms of the shapes they contain irrespective of light levels.\n\nHistogram equalization is often used to improve the statistics of images. In simple terms, the histogram equalization algorithm attempts to adjust the pixel values in the image to create a more uniform distribution. The code in the cell below uses the  **exposure.equalize_hist** method from the **skimage** package to equalize the image.  \n\n> You can ignore the warning displayed by this code"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom skimage import exposure\n%matplotlib inline\n\nimg_eq = exposure.equalize_hist(img1)\n\n# Display using matplotlib\n\n# Create a figure\nfig = plt.figure(figsize=(16, 8))\n\n# Subplot for original image\na=fig.add_subplot(1,2,1)\nimgplot = plt.imshow(img1)\na.set_title('Before')\n\n# Subplot for processed image\na=fig.add_subplot(1,2,2)\nimgplot = plt.imshow(img_eq)\na.set_title('After')\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As with most image operations, there's more than one way to do this. For example, you could also use the **PIL.ImgOps.equalize** method:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from PIL import Image, ImageOps\n%matplotlib inline\n\n# Equalize the image - but we need to convert the numpy array back to the PIL image format\nimgPIL_eq = ImageOps.equalize(Image.fromarray(img1))\n\n# Display using matplotlib\n\n# Create a figure\nfig = plt.figure(figsize=(16, 8))\n\n# Subplot for original image\na=fig.add_subplot(1,2,1)\nimgplot = plt.imshow(img1)\na.set_title('Before')\n\n# Subplot for processed image\na=fig.add_subplot(1,2,2)\nimgplot = plt.imshow(imgPIL_eq)\na.set_title('After')\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's see what that's done to the histogram and CDF plots:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Display histograms\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nfrom PIL import Image\n%matplotlib inline\n\nimg_eq = np.array(imgPIL_eq)\n\n# Create a figure\nfig = plt.figure(figsize=(16, 8))\n\n# Subplot for original image\na=fig.add_subplot(1,2,1)\nimgplot = plt.hist(img_eq.ravel())\na.set_title('Histogram')\n\n# Subplot for processed image\na=fig.add_subplot(1,2,2)\nimgplot = plt.hist(img_eq.ravel(), bins=255, cumulative=True)\na.set_title('CDF')\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The pixel intensities are more evenly distributed in the equalized image. In particular, the cumulative density shows a straight diagonal cumulation; which is a good sign that the pixel intensity values have been equalized."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Denoising with Filters\n\nOften images need to be cleaned up for analysis. One way to do this is to apply a filter.\n\nA filter is a small patch (or *kernel*) that is applied repeatedly (the correct term is *convolutionally*) across the image. For example, lets imaging this matrix represents a small, 1-dimensional image:\n\n$$\\begin{bmatrix}255 & 255 & 255 & 255 & 255 & 255\\\\255 & 255 & 125 & 125 & 255 & 255\\\\255 & 125 & 125 & 125 & 125 & 255\\\\255 & 125 & 125 & 125 & 125 & 255\\\\255 & 255 & 125 & 125 & 255 & 255\\\\255 & 255 & 255 & 255 & 255 & 255\\end{bmatrix}$$\n\nWe could process this image wih a 3x3 filter. The first application of the filter would be to the <span style=\"color:red\">red</span> pixels below:\n\n$$\\begin{bmatrix}\\color{red}{255} & \\color{red}{255} & \\color{red}{255} & 255 & 255 & 255\\\\\\color{red}{255} & \\color{red}{255} & \\color{red}{125} & 125 & 255 & 255\\\\\\color{red}{255} & \\color{red}{125} & \\color{red}{125} & 125 & 125 & 255\\\\255 & 125 & 125 & 125 & 125 & 255\\\\255 & 255 & 125 & 125 & 255 & 255\\\\255 & 255 & 255 & 255 & 255 & 255\\end{bmatrix}$$\n\nNow, let's suppose that this filter affects the image by recalculating the center pixel value as the mean of the pixel values in the kernel patch (this kind of filter is known as a *mean* filter and has the effect of blurring the image). Here's what that does to the first patch of the image:\n\n$$\\begin{bmatrix}\\color{red}{255} & \\color{red}{255} & \\color{red}{255} & 255 & 255 & 255\\\\\\color{red}{255} & \\color{blue}{212} & \\color{red}{125} & 125 & 255 & 255\\\\\\color{red}{255} & \\color{red}{125} & \\color{red}{125} & 125 & 125 & 255\\\\255 & 125 & 125 & 125 & 125 & 255\\\\255 & 255 & 125 & 125 & 255 & 255\\\\255 & 255 & 255 & 255 & 255 & 255\\end{bmatrix}$$\n\nThen we move the filter along and apply it to the next patch:\n\n$$\\begin{bmatrix}255 & \\color{red}{255} & \\color{red}{255} & \\color{red}{255} & 255 & 255\\\\255 & \\color{red}{212} & \\color{blue}{128} & \\color{red}{125} & 255 & 255\\\\255 & \\color{red}{125} & \\color{red}{125} & \\color{red}{125} & 125 & 255\\\\255 & 125 & 125 & 125 & 125 & 255\\\\255 & 255 & 125 & 125 & 255 & 255\\\\255 & 255 & 255 & 255 & 255 & 255\\end{bmatrix}$$\n\nThis process is repeated until the filter has been convolved across the entire image. Filtersv like this can be used to sharpen or blur images, and are often used to reduce the affect of *scatter* or *noise* in an image."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Add Some Random Noise\nTo see how this works, let's first add some random noise to our image - such as you might see in a photograph taken in low light or at a low resolution."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import skimage\n%matplotlib inline\n\nimg_n = skimage.util.random_noise(img_eq)\nplt.imshow(img_n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Using a Gaussian Filter\nA *Gaussian* filter is a slightly more complex version of a *mean* filter, with a similar blurring effect."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from scipy.ndimage.filters import gaussian_filter as gauss\n%matplotlib inline\n\nimg_gauss = gauss(img_n, sigma=1)   \nplt.imshow(img_gauss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Using a Median Filter\nThe Gaussian filter results in a blurred image, which may actually be better for feature extraction as it makes it easier to find contrasting areas. If it's too blurred, we could try a median filter, which as the name suggests applies the median value to the pixel in the center of the filter kernel."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from scipy.ndimage.filters import median_filter as med\n%matplotlib inline\n\nimg_med = med(img_n, size=2)\nplt.imshow(img_med)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Extract Features\nNow that we've done some initial processing of the image to improve its statistics for analysis, we can start to extract features from it.\n\n#### Sobel Edge Detection\nAs a first step in extracting features, you will apply the Sobel edge detection algorithm. This finds regions of the image with large gradient values in multiple directions. Regions with high omnidirectional gradient are likely to be edges or transitions in the pixel values. This works by performing two convolutional passes in which the pixel values are multiplied by the following filter kernels:\n\n$$\\text{Vertical}\\begin{bmatrix}-1 & \\:0 & \\:1\\\\-2 & \\:0 & \\:2\\\\-1 & \\:0 & \\:1\\end{bmatrix}$$\n\n$$\\text{Horizontal} \\begin{bmatrix}-1 & -2 & -1\\\\\\:0 & \\:0 & \\:0\\\\\\:1 & \\:2 & \\:1\\end{bmatrix}$$\n\nThe code in the cell below applies the Sobel algorithm to the median filtered image, using these steps:\n\n1. Convert the color image to grayscale for the gradient calculation since it is two dimensional.\n2. Compute the edge gradients in the x and y (horizontal and vertical) directions using the two kernels. \n3. Compute the magnitude of the gradient vectors identified by the filters.\n4. Normalize the gradient values. \n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def edge_sobel(image):\n    from scipy import ndimage\n    import skimage.color as sc\n    import numpy as np\n    image = sc.rgb2gray(image) # Convert color image to gray scale\n    dx = ndimage.sobel(image, 1)  # horizontal derivative\n    dy = ndimage.sobel(image, 0)  # vertical derivative\n    mag = np.hypot(dx, dy)  # magnitude\n    mag *= 255.0 / np.amax(mag)  # normalize (Q&D)\n    mag = mag.astype(np.uint8)\n    return mag\n\nimg_edge = edge_sobel(img_med)\nplt.imshow(img_edge, cmap=\"gray\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's try with the more blurred gaussian filtered image."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "img_edge = edge_sobel(img_gauss)\nplt.imshow(img_edge, cmap=\"gray\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that the lines are more pronounced. Although a gaussian filter makes the image blurred to human eyes, this blurring can actually help accentuate contrasting features for computer processing."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Harris Corner Detection\nAnother example of a feature extraction algorithm is corner detection. In simple terms, the Harris corner detection algorithm applies a filter that locates regions of the image with large changes in pixel values in all directions. These regions are said to be corners. The Harris corner detector is paired with the **corner_peaks** method. This operator filters the output of the Harris algorithm, over a patch of the image defined by the span of the filters, for the most likely corners."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Function to apply the Harris corner-detection algorithm to an image\ndef corner_harr(im, min_distance = 20):\n    import skimage.color as sc\n    from skimage.feature import corner_harris, corner_peaks\n    \n    im = sc.rgb2gray(im) # Convert color image to gray scale\n    mag = corner_harris(im)\n    return corner_peaks(mag, min_distance = min_distance)\n\n# Find the corners in the median filtered image with a minimum distance of 20 pixels\nharris = corner_harr(img_med, 20)\n\nprint (harris)\n\n# Function to plot the image with the harris corners marked on it\ndef plot_harris(im, harris, markersize = 20, color = 'red'):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    fig = plt.figure(figsize=(6, 6))\n    fig.clf()\n    ax = fig.gca()    \n    ax.imshow(np.array(im).astype(float), cmap=\"gray\")\n    ax.plot(harris[:, 1], harris[:, 0], 'r+', color = color, markersize=markersize)\n    return 'Done'  \n\nplot_harris(img_med, harris)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The corner detection algorithm has identified the eyes in the image.\n\n### Learn More\nPython supports a huge range of image manipulation functions that you can use to prepare images for analysis or machine learning. The links below will take you to the documentation for some of the most common image processing packages:\n\n[matplotlib](https://matplotlib.org/)\n\n[Python Imaging Library (PIL)](http://effbot.org/imagingbook/)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}