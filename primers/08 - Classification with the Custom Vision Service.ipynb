{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Using the Custom Vision Cognitive Servive\nThe *Custom Vision* cognitive service enables you to create a project in which you can train a classification model to identify images based on tags that you associate with them.\n\nIn this notebook, you will create and train a Custom Vision project that can identify pictures of apples and carrots, and use it to classify new images.\n\n*Some of the images used in the lab are sourced from the free image library at <a href='http://www.pachd.com' target='_blank'>www.pachd.com</a>*\n\n## Installing the Custom Vision SDK\nThe first step is to install the Python SDK for the Custom Vision service:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Install the Custom Vision SDK\n! pip install azure-cognitiveservices-vision-customvision",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Sign up for a Custom Vision service account\nNow you're ready to use the Custom Vision service. You'll need to sign up for an account and get your unique training and prediction keys so you can access it:\n1. If you don't already have a Microsoft Azure subscription, sign up at https://azure.microsoft.com/en-us/. \n2. Go to https://customvision.ai/ and sign in using your Microsoft account. Then create a new custom vision service account in your Azure subscription.\n3. Click the *Settings* (&#9881;) icon at the top right to view *training* and  *prediction* key's endpoints, and resource Ids. Then assign the appropriate values to the variables below and run the cell:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "TRAINING_KEY = 'YOUR_TRAINING_KEY'\nPREDICTION_KEY = 'YOUR_PREDICTION_KEY'\nENDPOINT='https://YOUR_REGION.api.cognitive.microsoft.com' # Use just the base URL - https://<region>.api.cognitive.microsoft.com\nPREDICTION_RESOURCE_ID=\"/subscriptions/YOUR_SUBSCRIPTION_ID/resourceGroups/YOUR_RESOURCE_GROUP/providers/Microsoft.CognitiveServices/accounts/YOUR_ACCOUNT_Prediction\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create a Custom Vision project\nOK, now it's time to create a project for the apple/carrot identifier:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n\ntrainer = CustomVisionTrainingClient(TRAINING_KEY, endpoint=ENDPOINT)\n\n# Create a new project\nprint (\"Creating project...\")\nproject = trainer.create_project(\"Produce Classification\")\nprint(\"Created project!\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Add tags\nThe project will identify images as apples or carrots, so we'll need tags for those classes:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Make two tags in the new project\nprint(\"Creating tags...\")\napple_tag = trainer.create_tag(project.id, \"Apple\")\ncarrot_tag = trainer.create_tag(project.id, \"Carrot\")\nprint('Created tags!')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Upload training images\nNow that we've got the tags, we need to upload some images of apples and carrots, assign the appropriate tags:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\nprint(\"Adding images...\")\n\napples_dir = \"data/apples\"\nfor image in os.listdir(os.fsencode(apples_dir)):\n    with open(apples_dir + \"/\" + os.fsdecode(image), mode=\"rb\") as img_data: \n        trainer.create_images_from_data(project.id, img_data.read(), [apple_tag.id])\n\ncarrots_dir = \"data/carrots\"\nfor image in os.listdir(os.fsencode(carrots_dir)):\n    with open(carrots_dir + \"/\" + os.fsdecode(image), mode=\"rb\") as img_data: \n        trainer.create_images_from_data(project.id, img_data.read(), [carrot_tag.id])\n        \nprint('Added images!')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Return to your Custom Vision service and click the *Home* (&#8962;) icon to return to the home page, and then open the ***Apple or Carrot*** project to view the images that have been uploaded and tagged.\n\n## Train the project\nWith the tagged images in place, we're now ready to train the project:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import time\n\nprint (\"Training...\")\n# Train the project, checking status every 1 second\niteration = trainer.train_project(project.id)\nwhile (iteration.status == \"Training\"):\n    iteration = trainer.get_iteration(project.id, iteration.id)\n    print (\"Training status: \" + iteration.status)\n    time.sleep(1)\n\n# The iteration is now trained. Publish it to the project endpoint\ntrainer.publish_iteration(project.id, iteration.id, \"First Iteration\", PREDICTION_RESOURCE_ID)\n\n# Make it the default iteration\niteration = trainer.update_iteration(project_id= project.id, iteration_id=iteration.id, name= \"First Iteration\", is_default=True)\n\nprint (\"Trained!\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Return to your Custom Vision service and click the **Performance** tab to view the *Precision* and *Recall* metrics for your trained project. These should be pretty high, even through we only used a few images.\n\n## Use the project to classify images\nNow that we have a trained project, we can use it to predict the class of new images that weren't in the training dataset:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n%matplotlib inline\n\n# Use two test images\ntest_img1_url = 'http://www.pachd.com/free-images/food-images/apple-01.jpg'\ntest_img2_url = 'http://www.pachd.com/free-images/food-images/carrot-02.jpg'\n\ntest_image_urls = []\ntest_image_urls.append(test_img1_url)\ntest_image_urls.append(test_img2_url)\n\n# Create an instance of the prediction service\npredictor = CustomVisionPredictionClient(PREDICTION_KEY, endpoint=ENDPOINT)\n\n# Create a figure\nfig = plt.figure(figsize=(16, 8))\n\n# Get the images and show the predicted classes\nfor url_idx in range(len(test_image_urls)):\n    response = requests.get(test_image_urls[url_idx])\n    image_contents = Image.open(BytesIO(response.content))\n    results = predictor.classify_image_url(project_id=project.id, published_name=iteration.name, url=test_img_url)\n    # The results include a prediction for each tag, in descending order of probability - so we'll get the first one\n    prediction = results.predictions[0].tag_name + \": {0:.2f}%\".format(results.predictions[0].probability * 100)\n    # Subplot for image and its predicted class\n    a=fig.add_subplot(1,2,url_idx+1)\n    imgplot = plt.imshow(image_contents)\n    a.set_title(prediction)\n\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Classify a local image\n\nPreviously, we predicted the class of an image based on a URL - what if you have the image as a local file?\n\nLet's download the test images:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get two test images\n!wget 'http://www.pachd.com/free-images/food-images/apple-01.jpg' -O \"data/test_apple.jpg\"\n!wget 'http://www.pachd.com/free-images/food-images/carrot-01.jpg' -O \"data/test_carrot.jpg\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we'll modify our prediction code a little to read the contents of the local image file and submit it to the Custom Vision service."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline\n\n# Use two test images\ntest_image1_file = os.path.join(\"data\", \"test_apple.jpg\")\ntest_image2_file = os.path.join(\"data\", \"test_carrot.jpg\")\n\ntest_images = []\ntest_images.append(test_image1_file)\ntest_images.append(test_image2_file)\n\n# Create an instance of the prediction service\npredictor = CustomVisionPredictionClient(PREDICTION_KEY, endpoint=ENDPOINT)\n\n# Create a figure\nfig = plt.figure(figsize=(16, 8))\n\n# Get the images and show the predicted classes\nfor idx in range(len(test_images)):\n    with open(test_images[idx], \"rb\") as image_contents:\n        results = predictor.classify_image(project.id, iteration.name, image_contents.read())\n    # The results include a prediction for each tag, in descending order of probability - so we'll get the first one\n    prediction = results.predictions[0].tag_name + \": {0:.2f}%\".format(results.predictions[0].probability * 100)\n    img = Image.open(test_images[idx])\n    # Subplot for image and its predicted class\n    a=fig.add_subplot(1,2,idx+1)\n    imgplot = plt.imshow(img)\n    a.set_title(prediction)\n\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Learn More\nCheck out the Custom Vision Service documentation at https://docs.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/home"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}