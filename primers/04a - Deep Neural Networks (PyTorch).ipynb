{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introduction to Deep Learning\nClassical machine learning relies on using statistics to determine relationships between features and labels, and can be very effective for creating predictive models. However, a massive growth in the availability of data coupled with advances in the computing technology required to process it has led to the emergence of new machine learning techniques that mimic the way the brain processes information in a structure called an artificial neural network.\n\nThe mathematics that underpins artificial neural networks can be complex if you haven't studied it before, and involves a combination of linear algebra and differential calculus. You don't really need to know the in-depth workings of this math in order to build machine learning models using modern ML frameworks, but a basic conceptual understanding can be helpful. The rest of this section consists of an overview of how neural networks work - if you already know this (or don't really care), skip to **Creating a Neural Network Model with PyTorch** below; otherwise, read on!\n\n## Neural Networks\nYour brain works by connecting networks of neurons, each of which receives electrochemical stimuli from multiple inputs, which cause the neuron to fire under certain conditions. When a neuron fires, it creates an electrochemical charge that is passed as an input to one or more other neurons, creating a complex *feed-forward* network made up of layers of neurons that pass the signal on.\n\n<br/>\n<div align=\"center\" style='font-size:24px;'>&#8694;&#9711;&rarr;</div>\n\nAn artificial neural network uses the same principles but the inputs are numeric values with associated *weights* that reflect their relative importance. The neuron calculates the product of these input values and weights, and applies them to an *activation function* that determines the numeric output that the artificial neuron produces.\n\n### Training a Neural Network\nAs the human brain learns from experience, the inputs to the neurons are strengthened or weakened depending on their importance to the decisions that the brain needs to make in response to stimuli. Similarly, you train an artificial neural network using a supervised leaning technique in which a *loss function* is used to evaluate how accurately the model outputs match known true values for the inputs that were passed to it, and then adjust the weights to make the outputs more accurate.\n\n### A Simplified Conceptual Example\nIf you're encountering deep neural networks for the first time, the concepts can seem very complex. Let's simplify things so we can visualize the basic principles more clearly using a very basic example. We'll use a single neuron that has a single input with an associated weight. Our goal is to determine the right value for the weight in order to get the expected output from the neuron. In this case, we know that an input value of **2.1** should produce an output value of **1**.\n\n<br/>\n<div align=\"center\" style='font-size:24px;'><sup>2.1</sup><sub>w</sub>&#8649;&#9711;&rarr;1</div>\n\nThe code in the following cell defines the neuron as a function that multiplies the the input (*X*) by the weight (*w*), and applies the result to a sigmoid activation function so that the output is squashed to a value between 0 and 1. We calculate the error (or *loss*) by simply subtracting the output generated for *X* (2.1) when using a weight of *w* from the expected true value (*Y*, which we know is 1), and squaring the result.\n\nThe code then calculate the derivative of the loss function with respect to the weight - don't worry too much about the actual math involved, the key point is that this enables us to determine in which direction (up or down) to adjust the weight in order to move the function output closer to the true value. If the derivative is negative, indicating that the function line is falling with respect to the weight, we'll increase the weight to make it fall further (bringing the loss down). If the function is rising with respect to the weight, we'll decrease it. We use a constant *learning rate* (*LR*) to specify by how much the weight is adjusted.\n\nTo train our single-neuron network, we initialize the weights with a random value and then repeatedly try generating an output from the function using our static input value (*X*) and the weight (*w*), calculating the loss, determining which way we need to adjust the weight to reduce the loss, and then trying again with a revised weight value. We finish after five iterations (*epochs*).\n\n> **Note:** The following code is a simplification of a neural network training process - in reality the network would include *bias* values and the loss function and optimizer would be more complex. This example is intended to simply illustrate the principles by which a neural network is trained by iteratively adjusting the weights applied to each neuron.\n\nRun the following cell to see the results:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport random\nfrom scipy.misc import derivative\n\n# Known values for input (feature) and output (label)\nX = 2.1\nY = 1\n\n# By how much should we adjust the weight with each iteration\nLR = 1\n\n# Neuron function\ndef neuron(x, w):\n    from scipy.special import expit as sigmoid\n    return sigmoid(x * w)\n\n# Function to calculate loss\ndef lossfunc(w):\n    return abs(Y - neuron(X, w)**2)\n\n# Initialize weight with a random value between 0 and 1\nw = random.uniform(0,1)\n\n# Call the function over 5 iterations (epochs), updating the weight and recording the loss each time\ne = 1\nweights = []\nlosses = []\nwhile e < 6:\n    print('Epoch:', e)\n    e += 1\n    weights.append(w)\n    print('\\tWeight:%.20f' % w)\n\n    # Pass the value and weight forward through the neuron\n    y = neuron(X, w)\n    print('\\tTrue value:%.20f' % Y)\n    print('\\tOutput value:%.20f' % y)\n\n    # Calculate loss\n    loss = lossfunc(w)\n    losses.append(loss)\n    print('\\tLoss: %.20f' % loss)\n\n    # Which way should we adjust w to reduce loss?\n    dw = derivative(lossfunc, w)\n    print('\\tDerivative:%.20f' % dw)\n\n    if dw > 0:\n        # Slope is positive - decrease w\n        w = w - LR\n    elif dw < 0:\n        # Slope is negative - increase w\n        w = w + LR\n\n# Plot the function and the weights and losses in our epochs\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Create an array of weight values\nwRange = np.linspace(-1, 7)\n\n# Use the function to get the corresponding loss values\nlRange = [lossfunc(i) for i in wRange]\n\n# Plot the function line\nplt.xlabel('Weight')\nplt.ylabel('Loss')\nplt.grid()\nplt.plot(wRange,lRange, color='grey', ls=\"--\")\n\n# Plot the weights and losses we recorded\nplt.scatter(weights,losses, c='red')\ne = 0\nwhile e < len(weights):\n    plt.annotate('E' + str(e+1),(weights[e], losses[e]))\n    e += 1\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Review the output from the code, and note that the loss should reduce after each epoch. The plotted line chart shows the loss function in grey and the weight/loss point for each epoch in red. For each epoch, the derivative of the loss function with respect to the weight tells us in which direction the slope (or *gradient*) of the function is headed, enabling us to determine how to adjust the weight to reduce the loss.\n\n## A More Detailed Look at Neural Networks\n\nNow that you've seen the basic concepts, it's time to consider artificial neural networks in more detail.\n\n\n### Weights and Bias\n\nOur previous example was based on a single neuron that had a single input. In reality, there are usually multiple inputs (each with its own weight), and there is also a *bias* value that is used to ensure the neuron only generates a significant output when appropriate. For example, suppose we represent a neuron that has two numeric inputs (let's call them *x<sub>1</sub>* and *x<sub>2</sub>*) each with an associated weight (*w<sub>1</sub>* and *w<sub>2</sub>*) and a bias input (*b*). Our artificial neuron will process these inputs within an activation function (let's call it *f*) like this:\n\n$$ f((x_{1} w_{1}) + (x_{2} w_{2}) + b) $$\n\nNow, let's assign the following values to our input variables:\n\n* *x<sub>1</sub>* = 3\n* *w<sub>1</sub>* = 0.2\n* *x<sub>2</sub>* = 1\n* *w<sub>2</sub>* = -0.5\n* *b* = 5\n\nOur neuron will therefore calculate:\n\n$$ f((3 \\times 0.2) + (1 \\times -0.5) + 5) $$\n\nWhich simplifies to:\n\n$$ f(0.6 - 0.5 + 5) $$\n\nOr:\n\n$$ f(5.1) $$\n\n### Activation Functions\nWe've calculated the product of our inputs relative to their weights and bias, so now we just need to apply our activation function to this. Generally an activation function is used to *squash* the output value to a value within a specific range. We want to function to be *smooth* so that it is differentiable, so it's common to use a *sigmoid* function that compresses the value along an *s-line* to a value between 0 and 1, or a *hyperbolic tangent (tanh)* function that produces a result between -1 and 1. Increasingly, *Rectified Linear Unit (ReLU)* functions that set all negative resuts to 0 are used as activation functions in deep neural networks.\n\nIn this example, let's use a **sigmoid** activation function:\n\n$$ S(5.1) \\approx 0.994$$\n\nSo the output of the activation function is (approximately) **0.994**.\n\n### Fully Connected Neural Network Layers\nNow that you understand how a single neuron works, let's see how these are combined into a neural network. The network consists of mulitple neurons organized in layers, like this:\n\n<div align=\"center\" style=\"font-size:18px;\">\n<table style=\"border-width:0px; background-color:white;\">\n    <tr><td style=\"border-width:0px; background-color:white;\"></td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8649;&#9711;&#10536;&#9711;&#11112;</td><td style=\"border-width:0px; background-color:white;\"></td></tr>\n    <tr><td style=\"border-width:0px; background-color:white;\"></td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8649;&#9711;&#10536;&#9711;&#10536;</td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8694;&#9711;&#8594;</td></tr>\n    <tr><td style=\"border-width:0px; background-color:white;font-size:18px;\">&rarr;&#9711;&#10536;</td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8649;&#9711;&#10536;&#9711;&#10536;</td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8694;&#9711;&#8594;</td></tr>\n    <tr><td style=\"border-width:0px; background-color:white;\"></td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8649;&#9711;&#10536;&#9711;&#10536;</td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8694;&#9711;&#8594;</td></tr>\n    <tr><td style=\"border-width:0px; background-color:white;\"></td><td style=\"border-width:0px; background-color:white;font-size:18px;\">&#8649;&#9711;&#10536;&#9711;&#11111;</td><td style=\"border-width:0px; background-color:white;\"></td></tr>\n    <tr><td>Input Layer</td><td>Hidden Layers</td><td>Output Layer</td></tr>\n</table>\n</div>\n\nThe *input layer* of the network consists of neurons that accept the initial input values of the data observation from which you want the network to generate a prediction - in other words, the initial set of *features*. The output of the input layer is passed to all of the neurons in the next layer, which can consist of as many neurons as you decide to include - in this case, five. The outputs from this layer are passed onto every neuron in the next layer, and so on; until finally, the flow of values ends in an *output layer* that contains one output for each possible class you are trying to predict (in this case, there are three possible classes that can be predicted by the network). The values in the output layers are generated by an activation function such that each value is between 0 and 1 and represents the probability of the observation belonging to each class - therefore the neuron in the output layer with the largest probability value represents the predicted class.\n\nThe layers in between the input and output layers are called *hidden layers*, because you have no visibility of the values being passed between these layers; and the network can consist of as many hidden layers as you decide to include. This kind of neural network, where the outputs from every neuron in each layer is passed as an input to every neuron in the next layer, is known as a *fully-connected* neural network - or sometimes as a *multi-layer perceptron*.\n\n### Training a Neural Network\nTraining a deep neural network with multiple layers, inputs, weights, and biases is conceptually the same as the example we saw previously where we trained a single neuron by determining a weight that minimizes loss when an input value with a known output value is processed.\n\nWe start by passing the feature values for a set of classes with known labels into the input layer of the network, and initially we use randomly assigned weights and biases to feed the data forward and eventually generate the output layer values. To make this managable, we generally break the input data into *batches* (often called *mini-batches*). For each batch, we can then use a loss function to calculate a numeric value representing the average loss by comparing the predicted values against the known true values.\n\nAfter we've processed multiple batches, and determined the overall loss, we can use differential calculus to find the derivative of the  loss with respect to the weights and biases that were used. Put more simply, we can determine what impact adjusting each weight and bias upward or downward will have on the loss. This process is called *backpropagation* (because it works backwards from the overall loss, using the *chain-rule* of calculus to calculate the derivatives for each layer with respect to the weights and biases). With these derivatives, we can determine in which direction to adjust the weights and biases to reduce the loss, using a techniques called *gradient descent*.\n\nWhen the impact of each weight and bias on the loss has been determined, the training process adjusts the weights and bias values so that the loss should decrease, and we repeat the process using the revised values. This cycle of feeding the data forward in batches, calculating the loss, and backpropagating to adjust the weights and biases is repeated (with each repetition of the cycle referred to as an *epoch*) to incrementally improve the accuracy of the model by reducing the overall loss.\n\n### Validation and Overfitting\nOne of the biggest challenges in machine learning is the problem of *overfitting*. This happens when the model learns the relationships between the features and labels in the test data by minimizing the loss during training; but doesn't generalize well to new data on which it wasn't trained. To detect overfitting, it's common to withhold some of the training data and use it to validate the model after each epoch. You can then calculate the loss from both the training data and the validation data and compare the two. If the training loss is reducing but the validation loss is stable (or worse, increasing), then the model is overfitting."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Creating a Neural Network with PyTorch\nPyTorch is a framework for creating machine learning models, including deep neural networks (DNNs). In this example, we'll use PyTorch to create a simple neural network that classifies iris flowers into species based on measurements of their petals and sepals.\n\n> The iris classification model is a very common machine learning example, and the iris dataset is often the basis for \"hello world\" sample code for a wide range of machine learning frameworks. In reality, you can solve this problem easily using classical machine learning techniques without the need for a deep learning model; but it's a useful, easy to understand dataset with which to demonstrate the principles of neural networks in this notebook.\n\n### Exploring the Iris Dataset\nBefore we start using PyTorch to create a model, let's examine the iris dataset. Since this is a commonly used sample dataset, it is built-in to the *scikit-learn* machine learning library, so we'll get it from there. As with any supervised learning problem, we'll then split the dataset into a set of records with which to train the model, and a smaller set with which to validate the trained model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\niris = datasets.load_iris()\n\n   \n# Split data 70%-30% into training set and test set\nx_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.40, random_state=0)\n\nprint ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\nprint(\"Sample of features and labels:\")\nprint('(features: ',iris.feature_names, ')')\n\n# Take a look at the first 25 training features and corresponding labels\nfor n in range(0,24):\n    print(x_train[n], y_train[n], '(' + iris.target_names[y_train[n]] + ')')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The *features* are the measurements for each iris observation, and the *label* is a numeric value that indicates the species of iris that the observation represents (versicolor, virginica, or setosa).\n\n### Importing the PyTorch Libraries\nSince we plan to use PyTorch to create our iris classifier, we'll need to install and import the PyTorch libraries we intend to use. The specific installation of of PyTorch depends on your operating system and whether your computer has graphics processing units (GPUs) that can be used for high-performance processing via *cuda*. You can find detailed instructions at https://pytorch.org/get-started/locally/."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install https://download.pytorch.org/whl/cpu/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n    \nimport torch\nimport torch.nn as nn\nimport torch.utils.data as utils\nimport torch.utils.data as td\nfrom torch.autograd import Variable\n\nprint(\"Libraries imported - ready to use PyTorch\", torch.__version__)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Prepare the Data for PyTorch\nPyTorch makes use of *data loaders* to load training and validation data in batches. We've already loaded the data into NumPy arrays, but we need to wrap those in PyTorch datasets (in which the data is converted to PyTorch *tensor* objects) and create loaders to read batches from those datasets."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create a dataset and loader for the training data and labels\ntrain_x = Variable(torch.Tensor(x_train).float())\ntrain_y = Variable(torch.Tensor(y_train).long())\ntrain_ds = utils.TensorDataset(train_x,train_y)\ntrain_loader = td.DataLoader(train_ds, batch_size=10,\n    shuffle=False, num_workers=1)\n\n# Create a dataset and loader for the test data and labels\ntest_x = Variable(torch.Tensor(x_test).float())\ntest_y = Variable(torch.Tensor(y_test).long())\ntest_ds = utils.TensorDataset(test_x,test_y)\ntest_loader = td.DataLoader(test_ds, batch_size=10,\n    shuffle=False, num_workers=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Define a Neural Network\nNow we're ready to define our neural network. In this case, we'll create a network that consists of 3 fully-connected layers:\n* An input layer that receives four input values (the iris features) and applies a *ReLU* activation function.\n* A hidden layer that receives ten inputs and applies a *ReLU* activation function.\n* An output layer that uses a *SoftMax* activation function to generate three outputs (which represent the probabilities for the three iris species)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Number of hidden layer nodes\nhl = 10\n\n# Define the neural network\nclass IrisNet(nn.Module):\n    def __init__(self):\n        super(IrisNet, self).__init__()\n        self.fc1 = nn.Linear(4, hl)\n        self.fc2 = nn.Linear(hl, hl)\n        self.fc3 = nn.Linear(hl, 3)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.softmax(self.fc3(x),dim=1)\n        return x\n\n# Create a model instance from the network\nmodel = IrisNet()\nprint(model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Train the Model\nTo train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n\nTo do this, we'll create a function to train and optimize the model, and function to test the model. Then we'll call these functions iteratively over 100 epochs, logging the loss and accuracy statistics for each epoch."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def train(model, data_loader, optimizer):\n    # Set the model to training mode\n    model.train()\n    train_loss = 0\n    \n    for batch, tensor in enumerate(data_loader):\n        data, target = tensor\n        #feedforward\n        optimizer.zero_grad()\n        out = model(data)\n        loss = loss_criteria(out, target)\n        train_loss += loss.item()\n\n        # backpropagate\n        loss.backward()\n        optimizer.step()\n\n    #Return loss\n    avg_loss = train_loss / len(data_loader.dataset)\n    return avg_loss\n           \n            \ndef test(model, data_loader):\n    # Switch the model to evaluation mode (so we don't backpropagate)\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for batch, tensor in enumerate(data_loader):\n            data, target = tensor\n            # Get the predictions\n            out = model(data)\n\n            # calculate the loss\n            test_loss += loss_criteria(out, target).item()\n\n            # Calculate the accuracy\n            _, predicted = torch.max(out.data, 1)\n            correct += torch.sum(target==predicted).item()\n            \n    # return validation loss and prediction accuracy for the epoch\n    avg_accuracy = correct / len(data_loader.dataset)\n    avg_loss = test_loss / len(data_loader.dataset)\n    return avg_loss, avg_accuracy\n       \n\n\n# Specify the loss criteria (CrossEntropyLoss for multi-class classification)\nloss_criteria = nn.CrossEntropyLoss()\n\n# Specify the optimizer (we'll use a Stochastic Gradient Descent optimizer)\nlearning_rate = 0.01\nlearning_momentum = 0.9\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=learning_momentum)\n\n# We'll track metrics for each epoch in these arrays\nepoch_nums = []\ntraining_loss = []\nvalidation_loss = []\n\n# Train over 100 epochs\nepochs = 100\nfor epoch in range(1, epochs + 1):\n    \n    # Feed the training data into the model to optimize the weights\n    train_loss = train(model, train_loader, optimizer)\n    \n    # Feed the test data into the model to check its performance\n    test_loss, accuracy = test(model, test_loader)\n    \n    # Log the metrcs for this epoch\n    epoch_nums.append(epoch)\n    training_loss.append(train_loss)\n    validation_loss.append(test_loss)\n    \n    # Print stats for every 10th epoch so we can see training progress\n    if (epoch) % 10 == 0:\n        print('Epoch {:d}: Training loss= {:.4f}, Validation loss= {:.4f}, Accuracy={:.4%}'.format(epoch, train_loss, test_loss, accuracy))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Review Training and Validation Loss\nAfter training is complete, we can examine the loss metrics we recorded while training and validating the model. We're really looking for two things:\n* The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels.\n* The training loss and validations loss should follow a similar trend, showing that the model is not overfitting to the training data.\n\nLet's plot the loss metrics and see:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nplt.plot(epoch_nums, training_loss)\nplt.plot(epoch_nums, validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training', 'validation'], loc='upper right')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### View the Learned Weights and Biases\nThe trained model consists of the final weights and biases that were determined by the optimizer during training. Based on our network model we should expect the following values for each layer:\n* Layer 1: There are four input values going to ten output nodes, so there should be 10 x 4 weights and 10 bias values.\n* Layer 2: There are ten input values going to ten output nodes, so there should be 10 x 10 weights and 10 bias values.\n* Layer 3: There are ten input values going to three output nodes, so there should be 3 x 10 weights and 3 bias values."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for param_tensor in model.state_dict():\n    print(param_tensor, \"\\n\", model.state_dict()[param_tensor].numpy())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Evaluate Model Performance\nSo, is the model any good? The raw accuracy reported from the validation data would seem to indicate that it predicts pretty well; but it's typically useful to dig a little deeper and compare the predictions for each possible class. A common way to visualize the performace of a classification model is to create a *confusion matrix* that shows a crosstab of correct and incorrect predictions for each class."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\nfrom sklearn.metrics import confusion_matrix\n\n# Set the model to evaluate mode\nmodel.eval()\n\n# Get predictions for the test data\nx = Variable(torch.Tensor(x_test).float())\n_, predicted = torch.max(model(x).data, 1)\n\n# Plot the confusion matrix\ncm = confusion_matrix(y_test, predicted.numpy())\nplt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(len(iris.target_names))\nplt.xticks(tick_marks, iris.target_names, rotation=45)\nplt.yticks(tick_marks, iris.target_names)\nplt.xlabel(\"Predicted Species\")\nplt.ylabel(\"True Species\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The confusion matrix should show a strong diagonal line indicating that there are more correct than incorrect predictions for each class.\n\n### Using the Model with New Data\nNow that we have a model we believe is reasonably accurate, we can use it to predict the species of new iris observations:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_new = [[6.6,3.2,5.8,2.4]]\nprint ('New sample: {}'.format(x_new))\n\nmodel.eval()\n\n# Get a prediction for the new data sample\nx = Variable(torch.Tensor(x_new).float())\n_, predicted = torch.max(model(x).data, 1)\n\nprint('Prediction:',iris.target_names[predicted.item()])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Learn More\nThis notebook was designed to help you understand the basic concepts and principles involved in deep neural networks, using a simple PyTorch example. To learn more about PyTorch, take a look at the <a href=\"https://pytorch.org/tutorials/\" target=\"_blank\">tutorials on the PyTorch web site</a>."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}